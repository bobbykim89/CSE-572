1. What is the goal of the Markov Decision Process?
- Maximize cumulative reward in the long run
    - Correct! Markov Decision Process wants to choose the policy which provided the highest amount of award in long term.

2. What is the reward computation approach for the Bellman equation?
- Discounted Rewards

3. What is a policy in Markov Decision Process (MDP)?
- It is a mapping from the set of states to the set of actions
  - correct! Policy entails what actions you can take in each state

4.  What are rewards used for in Markov Decision Process (MDP)? (select all that apply)
- To compare between policies.
  - Rewards are available for each action in a state. So, they can be used to evaluate policies, select actions or compare between policies. 
- To evaluate a policy.

5. What are some of the ways to solve the infinite reward problem? (Select all that apply)
- Only evaluate policies until a maximum time horizon is reached
  - Correct! Limiting the horizon can be used.
- Discounting factor
- Expected reward
  - Correct! Instead of cumulative reward, we can use expected reward. 